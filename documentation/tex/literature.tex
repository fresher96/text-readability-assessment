


\chapter{الدراسة المرجعية}
يبيّن هذا الفصل الدراسة المرجعية للمشروع.
يبدأ بتقديم مفاهيم تعلّم الآلة ومراحلها المختلفة والمعايير المعتمدة لتقييمها.
ويقدّم مفاهيم ومراحل معالجة اللغات الطبيعية.
وأخيراً يسرد بعض الأوراق الأبحاث العلمية المتعلقة بهذا المشروع، ويوضح المنهجيات المتبعة فيها.







\section{تعلم الآلة}
تعلم الآلة \textenglish{Machine Learning} هو فرع جزئي من الذكاء الصنعي \textenglish{Artificial Intelligence}.
يُقصد بتعلم الآلة مجموعة الأدوات والمفاهيم والمنهجيات المستخدمة لبرمجة الحواسيب
بطريقة تسمح لهذه الحواسيب بالتعلم من المعطيات.

ويمكن أيضاً تعريفه بشكل أكثر عمومية كالتالي:

\begin{english}
	``Machine Learning is the field of study that gives computers the ability to learn
	without being explicitly programmed.'' \\
	--Arthur Samuel, 1959
\end{english}

كما يعتبر التعريف التالي تقني وأكثر دقة:

\begin{english}
	``A computer program is said to learn from experience $E$ with respect to some task $T$
	and some performance measure $P$, if its performance on $T$, as measured by $P$, improves
	with experience $E$.'' \\
	--Tom Mitchell, 1997
\end{english}

على سبيل المثال، النظام الذي يقوم بفلترة الإيميلات إلى إيميلات مؤذية \textenglish{spam} وإيميلات غير مؤذية \textenglish{non-spam}، يستخدم منهجيات تعلم الآلة.
يقوم هذا النظام بتعلم طريقة التمييز بين هذين النوعين من الإيميلات باستخدام عدد كبير من الأمثلة والمعطيات المصنفة مسبقاً.
نسمي هذه المجموعة من الأمثلة بمعطيات التدريب \textenglish{Training Set}، وكل مثال منها نسميه مثال تدريبي \textenglish{Training Instance}.

في هذه الحالة، المهمة $T$ هي تصنيف الإيميلات الجديدة إلى إيميلات مؤذية وإيميلات غير مؤذية، الخبرة $E$ هي مجموعة معطيات التدريب،
ومؤشر قياس الأداء $P$ يمكن تعريفه بعدّة طرق؛ فمثلاً يمكننا استخدام نسبة نسبة عدد الإيميلات التي تم تصنيفها بشكل صحيح إلى عدد الإيميلات الكلي
(هذا المعيار يسمى الدقّة \textenglish{Accuracy} كم سنرى لاحقاً).

\subsection{تصنيفات تعلم الآلة}
\label{sec:ml:classification}
يمكن تصنيف أنظمة تعلم الآلة وفق عدّة معايير. التصنيف الأكثر شهرة يعتمد على آلية التدريب، وهو كالتالي:
\begin{itemize}
	\item
	التعلم تحت الإشراف \textenglish{Supervised Learning}:
	وهي حالة أن تكون الأمثلة التدريبية متوفرة مع الخرج \textenglish{label} المرتبط بها. وهذه حالة مثال تصنيف الإيميلات المطروح سابقاً.
	حيث أن معطيات التدريب هي مجموعة كبيرة من الإيميلات المصنفة مسبقاً من قبل البشر إلى إيميلات مؤذية وإيميلات غير مؤذية.
	\item
	التعلم بدون إشراف \textenglish{Unsupervised Learning}:
	وهي حالة أن تكون معطيات التدريب موجودة ولكنها غير مصنفة \textenglish{unlabeled} أو غير مرتبطة بخرج معيّن.
	على سبيل المثال، قد ترغب شركة في تصنيف زبائنها إلى عدّة مستويات، زبائن من الدرجة الأولى، زبائن من الدرجة الثانية، وهكذا.
	فيمكن استخدام تعلم الآلة لاكتشاف بعض الأنماط الموجودة في معطيات الزبائن واكتشاف هكذا تصنيف.
	وهذا ما يُعرف بالتجميع \textenglish{Clustering}.
	\item
	التعلم نصف المشرف عليه \textenglish{Semi-Supervised Learning}:
	وهي حالة وسيطة بين التصنيفين السابقين. تكون فيها بعض أمثلة التدريب مرتبطة بخرج معيّن (غالباً تشكل النسبة الصغيرة)،
	وتكون باقي الأمثلة غير مرتبطة بخرج. تنطبق هذه الحالة على مثال تصنيف الإيميلات في حال لم تكن جميع معطيات التدريب مصنفة بشكل مسبق.
	\item 
	التعلم بالتعزيز \textenglish{Reinforcement Learning}:
	وهي الحالة التي يتخاطب فيها النظام مع بيئة أخرى. تقدم له هذه البيئة نتائج \textenglish{feedback} بناءً على أفعاله.
	هذا الصنف ينطبق على الخوارزميات المستخدمة لتدريب الأنظمة التي تتعلم الألعاب.
	حيث يقوم النظام بمجموعة من الأفعال \textenglish{actions} ضمن بيئة اللعبة،
	وبناءً على النتائج (تحسّن نتيجته أو انخفاضها) يغيّر أفعاله اللاحقة.
\end{itemize}

وعلى وجه الخصوص يمكن تصنيف التعلم تحت الإشراف بحسب نوع الخرج المرتبط بمعطيات التدريب.
تصنّف بشكل أساسي عريض كالتالي:
\begin{itemize}
	\item 
	التصنيف \textenglish{Classification}:
	يكون الخرج المرتبط بكل مثال تدريبي هو صف \textenglish{class} محدد من مجموعة صفوف. عدد هذه الصفوف قد يكون $2$، $3$، إلخ.
	في مثال تصنيف الإيميلات السابق، عدد الصفوف هو $2$، حيث أن كل مثال تدريبي (إيميل معيّن من معطيات التدريب) هو إمّا مؤذي أو غير مؤذي.
	\item 
	الانحدار \textenglish{Regression}:
	يكون الخرج المرتبط بكل مثال تدريبي هو عدد حقيقي. مثل مسألة التنبؤ بسعر منزل بمعرفة معلومات عنه مثل مساحته، عدد الغرف، إلخ.
\end{itemize}






\subsection{المراحل اللازمة لتطبيق تعلم الآلة}
\label{sec:ml:steps}
إذا عدنا إلى مثال تصنيف الإيميلات، حيث قلنا أن معطيات التدريب هي مجموعة من الإيميلات المصنفة بشكل مسبق إلى إيميلات مؤذية وإيميلات غير مؤذية.
يمكن أن نسأل هنا: ما هو تحديداً الدخل؟ أي كيف سنعبّر عن الإيميل؟ بالطبع يمكن اعتبار الإيميل كنص؛ فهو مجموعة من الكلمات والرموز.
ولكن كما سنرى لاحقاً، من الصعب على معظم خوارزميات تعلم الآلة التعامل مع نص خام. ولذلك هناك مرحلة تسبق مرحلة تنفيذ خوارزميات تعلم الآلة
وهي مرحلة تحويل النص إلى ما يسمى بالميزات \textenglish{Features}.

فمثلاً يمكن أن نعبّر عن نص الإيميل بميزاته، مثل عدد الكلمات، عدد الجمل،
تواتر وجود كلمات مفتاحية محددة، إلخ. نلاحظ الآن في هذه الحالة أننا نتعامل مع الإيميل كشعاع من الميزات \textenglish{feature vector} وهذا أمر مناسب جداً
للعديد من خوارزميات تعلم الآلة. أيضاً إن الميزات التي ذكرناها هي ميزات عددية \textenglish{numerical features}، ولكن بشكل عام يمكن أن تكون الميزات
هي ميزات نصية \textenglish{string features} أو ميزات صنفية \textenglish{categorical features}، إلخ. ويمكن أيضاً تنميط الميزات بشكل مختلف أو أكثر دقة
مثل تصنيف الميزات العددية إلى ميزات مستمرة \textenglish{continuous features} وميزات متقطعة \textenglish{discrete features}. وتعود طريقة التنميط إلى
التطبيق أو خوارزميات تعلم الآلة المستخدمة. تسمى هذه المرحلة بمرحلة استخراج الميزات \textenglish{Feature Extraction}.

في التطبيقات الواقعية تسبق المرحلة السابقة مرحلتين أساسيتين. مرحلة تجميع المعطيات، ومرحلة تنظيفها. تتم عملية تجميع المعطيات بحسب التطبيق.
فمثلاً قد تكون المعطيات هي نتيجة استبيانات، أو إحصائيات، أو تم الحصول عليها من مواقع إلكترونية، إلخ.
مرحلة تنظيف المعطيات تهدف إلى التأكد سلامة المعطيات قبل استخدامها. وقد تتم هذه العملية بشكل يدوي أو بشكل مؤتمت وذلك بحسب مصدر المعطيات ونظافتها.




\subsection{خوارزميات تعلم الآلة}
كما رأينا في الفقرة \ref{sec:ml:classification}، هناك العديد من أصناف المسائل الممكن حلها باستخدام تعلم الآلة.
تصنف خوارزميات تعلم الآلة تبعاً لصنف المسألة التي تقوم بحلها. فمثلاً يمكن استخدام الانحدار الخطي
\textenglish{Linear Regression}
لحل مسائل الانحدار \cite{hands-on}.
أو استخدام خوارزمية \textenglish{K-Means Clustering}  لحل مسائل التجميع \cite{hands-on}.
 
سنمهد في هذه الفقرة لأهم الخوارزميات المستخدمة في هذا المشروع.
وهي: \textenglish{J48}و\textenglish{SVM}.
وجب التنويه إلى أنه تم النظر إلى المسألة المطروحة في هذا المشروع على أنها مسألة تصنيف، انظر إلى الفقرة
%todo


\subsubsection{J48}

\subsubsection{SVM}
إن كلمة \textenglish{SVM} هي اختصار لـ \textenglish{Support Vector Machine}.
وهي خوارزمية شهيرة وواسعة الاستخدام في تطبيقات تعلم الآلة.
تعتبر خوارزمية قوية حيث أنها تستند على أساس رياضي متين، ولها عدد من الخصائص المهمّة.
يمكن تقديم هذه الخوارزمية بعدّة طرق.
سنقدمها بطرح مسألة الأملثة التي تقوم بحلها.

بدايةً لنفرض أن مسألتنا هي مسألة تصنيف وعدد الصفوف هو $2$.
نرمز بـ
$(x^{(i)}, y^{(i)})_{1 \leq i \leq m}$
إلى معطيات التدريب.
حيث $m$ عدد معطيات التدريب.
ويكون المثال التدريبي رقم $i$، له الصف $ y^{(i)} $.
مع كون $ y^{(i)} = +1 $ في حال الصف الأول، و $ y^{(i)} = -1 $ في حال الصف الثاني.
وإن $ x^{(i)} $ هو شعاع عددي بـ $ n+1 $ بُعد أي
$ x^{(i)} \in \mathbb{R}^{n+1} $%
. وهو ما سميناه شعاع الميزات، انظر الفقرة \ref{sec:ml:steps}.
أي هنا لدينا $n$ ميزة، حيث للسهولة نضيف $ x^{(i)}_0 = 1 $.

النموذج المطروح في خوارزمية الـ \textenglish{SVM}، هو تعريف تابع 
$ f: \mathbb{R}^{n+1} \rightarrow \{-1, +1 \} $%
. حيث أننا نقول أنه لأجل عيّنة ما $ (x, y) $ فإنها ينتمي إلى الصف الأول في حال كان $ f(x) \geq 0 $،
وينتمي إلى الصف الثاني في حال $ f(x) < 0 $.
سنأخذ مبدئياً للتبسيط التابع $f$ بالشكل
$ f(x) = \theta_0 x_0 + \theta_1 x_1 + \dots + \theta_n x_n $
حيث
$ \theta = (\theta_j)_{0 \leq j \leq n} $
هي البارامترات التي يمكن تغييرها.

مسألة الأمثلة التي نريد حلها هي:
\begin{align}
\label{eq:svm:primal}
&
\argmin_{\theta \in \mathbb{R}^{n+1} } \left(
\norm{\theta}^2 +
C \cdot \sum_{i = 1}^{m} \pospart{1 - y^{(i)} f(x^{(i)})}
\right)
\\
&
\operatorname{where}
f(x^{(i)}) = \sum_{j = 0}^{n} \theta_j x^{(i)}_j
\nonumber
\end{align}
حيث أن التابع
$\pospart{\cdot}$
هو تابع الجزء الموجب؛ أي
$ \pospart{z} = \max(z, 0) $%
. و
 $ \norm{\cdot} $
 هو النظيم الإقليدي؛ أي
 $ \norm{\theta}^2 = \sum_{j=0}^{n} \theta_j^2 $%
 . والباراميتر $C$ هو معامل وزن، يحدد مدى التفضيل والمساومة بين الحديّن الأول والثاني في المعادلة.
 
 إن الحد الأول $ \norm{\theta}^2 $ في المعادلة \ref{eq:svm:primal} هو للتنظيم \textenglish{Regularization}.
 هذا يضبط قيم البارميتر $ \theta $ ويمنعها من أن تأخذ قيم كبيرة.
 الحد الثاني يمثل مجموعة قيمة الخطأ الحاصل في كل مثال تدريبي من معطيات التدريب.
 حيث أن الخطأ الحاصل في عيّنة ما $ (x, y) $ هو
 $ \pospart{1 - y \cdot f(x)} $
يمكن تأمل صفات هذا الخطأ من خلال الشكل \ref{fig:svm:error}.
حيث نلاحظ مثلاً في حالة $ y = 1 $ أن الخطأ يساوي الصفر عندما $ f(x) \geq 1 $ 
وأنه يتزايد بشكل خطي كلما أبتعدت قيمة $ f(x) $ عن $1$ بالاتجاه الخاطئ.
 \begin{figure}[htb]
 	\centering
 	\includegraphics[width=0.2\linewidth]{images/HIAST_logo.JPG}
 	\caption[short]{long}
 	\label{fig:svm:error}
 \end{figure}
 
يوجد شكل آخر لمسألة الأمثلة التي تحلها خوارزمية الـ \eng{SVM} وهو:
\begin{align}
\argmax_{\theta} \left(
\sum_{i=1}^{m} \theta_i -
\frac{1}{2} \sum_{i=1}^{m} \sum_{k=1}^{m}
\theta_i \theta_k y^{(i)} y^{(k)} K(x^{(i)}, x^{(k)})
\right)
\\
\operatorname{subject \ to} \left(
\sum_{i=1}^{m} \theta_i y^{(i)} = 0
\bigwedge
0 \leq \theta_i \leq C : i = 1, \dots, m
\right)
\nonumber
\end{align}
حيث يسمى التابع $K$ بالنواة \eng{Kernel}.
لكن نلاحظ أنه في هذه المعادلة لدينا $ m+1 $ متحول عوض $ n+1 $ متحول.
وفي هذه الحالة يكون
$ f(x) = \sum_{i=1}^{m} \theta_i K(x, x^{(i)}) + \theta_0 $


 